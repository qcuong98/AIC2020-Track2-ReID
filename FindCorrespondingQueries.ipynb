{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoader\n",
    "from datasets import ImageFolderDataset\n",
    "import csv\n",
    "\n",
    "query_folder = '../AIC20_ReID/image_query'\n",
    "query_csv = 'metadata/Label-Test-Query - Query.csv'\n",
    "\n",
    "size = (224, 224)\n",
    "query_images = []\n",
    "\n",
    "# with open(query_csv, 'r') as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file)\n",
    "#     header = next(csv_reader)\n",
    "#     for row in csv_reader:\n",
    "#         image_name, cluster_code = row[0], row[5]\n",
    "#         cluster = cluster_code.split(\"_\")[2]\n",
    "#         if int(cluster) > 0 and int(cluster) <= 50:\n",
    "#             query_images.append(image_name)\n",
    "from pathlib import Path\n",
    "for file_name in Path(query_folder).glob('*.jpg'):\n",
    "    query_images.append(str(file_name.parts[-1]))\n",
    "            \n",
    "query_dataset = ImageFolderDataset(query_folder, query_images, query_images,\n",
    "                                   transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),  \n",
    "                                        transforms.ToTensor()\n",
    "                                   ]))\n",
    "    \n",
    "batch_size = 8\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "query_loader = torch.utils.data.DataLoader(query_dataset, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuong/AIC20-Track2/venv/lib/python3.6/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_path = 'weights/onlinetriplet-b4-200405-hardest_30epochs.pth'\n",
    "model = torch.load(model_path)\n",
    "# feature_extractor = model.embedding_net\n",
    "feature_extractor = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DIMS = 1792\n",
    "def extract_embeddings(dataloader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), N_DIMS))\n",
    "        labels = []\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels += target\n",
    "            k += len(images)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding, query_labels = extract_embeddings(query_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist_torch(emb1, emb2):\n",
    "    m, n = emb1.shape[0], emb2.shape[0]\n",
    "    emb1_pow = torch.pow(emb1, 2).sum(dim = 1, keepdim = True).expand(m, n)\n",
    "    emb2_pow = torch.pow(emb2, 2).sum(dim = 1, keepdim = True).expand(n, m).t()\n",
    "    dist_mtx = emb1_pow + emb2_pow\n",
    "    dist_mtx = dist_mtx.addmm_(1, -2, emb1, emb2.t())\n",
    "    dist_mtx = dist_mtx.clamp(min = 1e-12).sqrt()\n",
    "    return dist_mtx\n",
    "\n",
    "def run_query_query(emb_query):\n",
    "    #Calculate distance matrix between query images and gallery images\n",
    "    dist_mtx = pdist_torch(emb_query, emb_query).cpu().detach().numpy()\n",
    "    return dist_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding_indices = np.argsort(np.asarray(query_labels))\n",
    "query_embedding_sorted = np.asarray([query_embedding[i] for i in query_embedding_indices])\n",
    "query_labels_sorted = np.asarray([query_labels[i] for i in query_embedding_indices])\n",
    "\n",
    "query_tensor = torch.from_numpy(query_embedding_sorted)\n",
    "if cuda:\n",
    "    query_tensor = query_tensor.cuda()\n",
    "    \n",
    "dists = run_query_query(query_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 345]\n",
      "[1, 900]\n",
      "[3, 135]\n",
      "[4, 539]\n",
      "[5, 1037, 542, 514, 793, 523, 251, 774, 1013]\n",
      "[7, 571, 747, 824]\n",
      "[9, 319, 981]\n",
      "[11, 248, 151, 498, 1022]\n",
      "[21, 488, 889]\n",
      "[29, 490]\n",
      "[31, 70, 243, 275, 181, 309, 497]\n",
      "[32, 472, 106]\n",
      "[33, 94]\n",
      "[37, 261, 954, 990]\n",
      "[39, 983]\n",
      "[43, 272, 294, 289]\n",
      "[45, 105, 196, 212]\n",
      "[46, 137, 350, 565, 473]\n",
      "[49, 819, 1012]\n",
      "[51, 448, 446, 519]\n",
      "[52, 450]\n",
      "[58, 626, 998, 74, 264, 648]\n",
      "[61, 563]\n",
      "[64, 256, 315, 642, 969]\n",
      "[65, 879, 407, 1021]\n",
      "[67, 804, 422, 524, 569, 742, 608, 903]\n",
      "[68, 505, 335, 424, 810, 1000, 361, 147, 439, 910, 171, 568, 541, 849]\n",
      "[71, 790]\n",
      "[73, 202, 484, 817, 529, 285, 97, 242, 999, 600]\n",
      "[78, 988, 1040]\n",
      "[82, 940, 979]\n",
      "[83, 829]\n",
      "[88, 180, 102, 937, 796, 984]\n",
      "[90, 177]\n",
      "[91, 404, 872, 504]\n",
      "[95, 663]\n",
      "[98, 591, 672]\n",
      "[104, 176, 935]\n",
      "[109, 110, 694, 339, 1019]\n",
      "[111, 353, 651, 919]\n",
      "[114, 220, 1042, 582, 455, 559, 400, 526, 870, 907, 675, 486, 164]\n",
      "[115, 797]\n",
      "[117, 310]\n",
      "[119, 507, 697, 780]\n",
      "[123, 252, 138]\n",
      "[124, 166]\n",
      "[126, 366, 532]\n",
      "[127, 317]\n",
      "[129, 442, 767]\n",
      "[136, 230, 894]\n",
      "[140, 586]\n",
      "[141, 650, 949]\n",
      "[143, 843]\n",
      "[146, 888, 815]\n",
      "[148, 1017]\n",
      "[153, 276, 286, 854, 893]\n",
      "[155, 708]\n",
      "[163, 291]\n",
      "[165, 480, 411, 781, 474, 703, 847]\n",
      "[168, 503]\n",
      "[170, 433, 470, 944]\n",
      "[178, 926]\n",
      "[179, 387]\n",
      "[183, 219, 632]\n",
      "[187, 278, 763, 809]\n",
      "[191, 778]\n",
      "[193, 1011]\n",
      "[198, 1005]\n",
      "[205, 456, 920, 1032]\n",
      "[208, 356]\n",
      "[215, 384, 895, 939, 290]\n",
      "[221, 462, 334]\n",
      "[224, 912, 362]\n",
      "[228, 677]\n",
      "[229, 1015]\n",
      "[233, 336, 499]\n",
      "[235, 502, 557, 1026, 624]\n",
      "[236, 408]\n",
      "[238, 427, 921, 862]\n",
      "[244, 344]\n",
      "[245, 465, 638, 946, 376, 967, 656]\n",
      "[246, 445, 515, 487, 520, 925]\n",
      "[258, 288, 562, 478]\n",
      "[265, 418, 959]\n",
      "[269, 880]\n",
      "[270, 399, 911]\n",
      "[279, 508, 595, 962, 1010]\n",
      "[282, 738]\n",
      "[292, 951, 869]\n",
      "[293, 846, 771]\n",
      "[301, 343]\n",
      "[311, 367]\n",
      "[316, 383, 360, 1027]\n",
      "[342, 598, 814]\n",
      "[346, 807]\n",
      "[348, 403, 1030, 657, 531]\n",
      "[354, 803]\n",
      "[358, 878]\n",
      "[382, 461]\n",
      "[385, 825]\n",
      "[391, 821]\n",
      "[392, 434]\n",
      "[397, 916]\n",
      "[429, 699]\n",
      "[431, 589, 722, 760]\n",
      "[436, 823]\n",
      "[437, 795, 961]\n",
      "[451, 830, 858]\n",
      "[469, 492]\n",
      "[475, 667]\n",
      "[476, 481, 1031]\n",
      "[477, 702, 800, 905]\n",
      "[494, 754, 938, 685]\n",
      "[512, 997, 995]\n",
      "[525, 615]\n",
      "[527, 856]\n",
      "[545, 861]\n",
      "[546, 578]\n",
      "[555, 927]\n",
      "[573, 613, 637, 877, 1020]\n",
      "[580, 625]\n",
      "[597, 845]\n",
      "[606, 784]\n",
      "[618, 794]\n",
      "[628, 1002]\n",
      "[641, 751]\n",
      "[654, 897, 712]\n",
      "[658, 866, 1033]\n",
      "[664, 1018]\n",
      "[678, 928]\n",
      "[679, 941]\n",
      "[686, 783]\n",
      "[690, 805]\n",
      "[715, 787]\n",
      "[733, 952]\n",
      "[748, 882, 968, 972]\n",
      "[769, 898]\n",
      "[786, 808, 837, 892]\n",
      "[801, 1001]\n",
      "[820, 1036]\n",
      "[834, 868]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "n_queries = len(query_labels_sorted)\n",
    "\n",
    "mark = [False for i in range(n_queries)]\n",
    "\n",
    "def DFS(u, component):\n",
    "    mark[u] = True\n",
    "    component.append(u)\n",
    "    for v in range(n_queries):\n",
    "        if not mark[v] and dists[u][v] < threshold:\n",
    "            DFS(v, component)\n",
    "\n",
    "components = []\n",
    "for idx in range(n_queries):\n",
    "    if not mark[idx]:\n",
    "        components.append([])\n",
    "        DFS(idx, components[-1])\n",
    "\n",
    "for component in components:\n",
    "    if len(component) > 1:\n",
    "        print(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "output_path = '../full_query_groups'\n",
    "\n",
    "os.mkdir(output_path)\n",
    "\n",
    "for idx, component in enumerate(components):\n",
    "    group_path = os.path.join(output_path, str(idx)) \n",
    "    os.mkdir(group_path)\n",
    "    for vertical in component:\n",
    "        copyfile(os.path.join(query_folder, query_labels_sorted[vertical]), \n",
    "                 os.path.join(group_path, query_labels_sorted[vertical]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
