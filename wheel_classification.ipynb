{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "MIN_KEYPOINTS = 30\n",
    "N_CLUSTERS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_list_img(imgs):\n",
    "    \"\"\" Visualize list of image in one row \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(imgs), figsize=(20, 8 * len(imgs)))\n",
    "    for img, ax in zip(imgs, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words(img, feature_detector):\n",
    "    \"\"\" Create bags of visual word from img \"\"\"\n",
    "    \n",
    "    keypoints, descriptors = feature_detector.detectAndCompute(img, None)\n",
    "    if len(keypoints) < MIN_KEYPOINTS:\n",
    "        return None\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find K mean cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from pathlib import Path\n",
    "\n",
    "def load_bov_files(input_folder):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "        input_folder: str: Path to folder you want to bag of visual word\n",
    "        \n",
    "    Return: \n",
    "        bovs (dict): Mapping from fname to list visual words \n",
    "    \"\"\"\n",
    "    bovs = {}\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    cnt_file, cnt_word = 0, 0\n",
    "    for filename in Path(input_folder).glob(\"**/*.jpg\"):\n",
    "        cnt_file += 1\n",
    "        fname = os.path.join(str(filename.parts[-2]), str(filename.parts[-1]))\n",
    "        img = cv2.imread(str(filename))\n",
    "        visual_words = get_visual_words(img, sift)    \n",
    "        if visual_words is not None:\n",
    "            bovs[fname] = visual_words\n",
    "            cnt_word += 1\n",
    "    print(\"Number of files that have words: %s / %s\" % (cnt_word, cnt_file))\n",
    "    return bovs\n",
    "\n",
    "def find_k_mean_clusters(bovs, n_cluster=6):\n",
    "    \"\"\" Find kmean cluster from bovs dictionary \"\"\"\n",
    "    arr_bov = []\n",
    "    for v in bovs.values():\n",
    "        arr_bov.extend(v)\n",
    "    \n",
    "    kmean = KMeans(n_cluster)\n",
    "    kmean.fit(arr_bov)\n",
    "    return kmean   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hist(x, n_bins):\n",
    "    \"\"\" Build histogram \"\"\"\n",
    "    hist = np.zeros(n_bins)\n",
    "    for value in x:\n",
    "        hist[value] += 1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files that have words: 1616 / 2692\n",
      "Load success\n"
     ]
    }
   ],
   "source": [
    "input_folder = '/home/qcuong98/Desktop/ReID/attributes/Wheel_Test/'\n",
    "bovs = load_bov_files(input_folder)\n",
    "\n",
    "print(\"Load success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean = find_k_mean_clusters(bovs, N_CLUSTERS)\n",
    "# import pickle\n",
    "# pickle.dump(kmean, open(\"BoW_pickles/wheel_kmean_200_clusters.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "kmean = pickle.load(open(\"BoW_pickles/wheel_kmean_200_clusters.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_distance(x1, x2):\n",
    "    return np.sum((x1 - x2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(bovs, kmean, f1):\n",
    "    rank = [k for k in bovs]\n",
    "    rank = sorted(rank, key = lambda f2: compare_l2(kmean, bovs[f1], bovs[f2]))\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {}\n",
    "for k, v in bovs.items():\n",
    "    h = kmean.predict(v)\n",
    "    h = build_hist(h, N_CLUSTERS)\n",
    "    hists[k] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "query_folder = '/home/qcuong98/Desktop/ReID/attributes/Wheel_Query/Cropped'\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "sum_dist = np.zeros((1052, 798))\n",
    "cnt_dist = np.zeros((1052, 798))\n",
    "\n",
    "reference_path = '/media/qcuong98/BackUp1/Dataset/AIC20_track2_reid/AIC20_track2/AIC20_ReID/test_track.txt'\n",
    "reference = open(reference_path).readlines()\n",
    "tracks = np.array([x.strip().split()\n",
    "                   for x in reference if len(x.strip()) != 0])\n",
    "tracklet_ids = np.arange(len(tracks))\n",
    "veh2tracklet_mapping = {v: i for i, x in enumerate(tracks) for v in x}\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# pbar = tqdm([filename for filename in Path(query_folder).glob(\"**/*.jpg\")])\n",
    "pbar = [filename for filename in Path(query_folder).glob(\"**/*.jpg\")]\n",
    "cnt = 0\n",
    "for filename in pbar:\n",
    "    cnt += 1\n",
    "    if (cnt % 100 == 0):\n",
    "        print(cnt)\n",
    "        \n",
    "    query_id = int(str(filename.parts[-2]))\n",
    "    img = cv2.imread(str(filename))\n",
    "    visual_words = get_visual_words(img, sift)  \n",
    "    if visual_words is not None:\n",
    "        hist = kmean.predict(visual_words)\n",
    "        hist = build_hist(hist, N_CLUSTERS)\n",
    "        for k, v in hists.items():\n",
    "            gallery_name = k[:6] + \".jpg\"\n",
    "            tracklet_id = veh2tracklet_mapping[gallery_name]\n",
    "            sum_dist[query_id - 1][tracklet_id] += l2_distance(hist, v)\n",
    "            cnt_dist[query_id - 1][tracklet_id] += 1\n",
    "            \n",
    "# dist_matrix = np.fill((1052, 798), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUERIES = 1052\n",
    "N_TRACKLETS = 798\n",
    "\n",
    "dist = np.full((N_QUERIES, N_TRACKLETS), np.nan)\n",
    "np.divide(sum_dist, cnt_dist, out=dist, where=cnt_dist != 0)\n",
    "\n",
    "n_nan = np.zeros(N_QUERIES)\n",
    "for i in range(N_QUERIES):\n",
    "    for j in range(N_TRACKLETS):\n",
    "        if not np.isnan(dist[i][j]):\n",
    "            n_nan[i] += 1\n",
    "\n",
    "scores = np.full((N_QUERIES, N_TRACKLETS), np.nan)\n",
    "indices = np.argsort(dist, axis = 1)\n",
    "for i in range(N_QUERIES):\n",
    "    for j in range(N_TRACKLETS):\n",
    "        if not np.isnan(dist[i][indices[i][j]]):\n",
    "            scores[i][indices[i][j]] = 1 - (j / n_nan[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.05925926        nan        nan 0.54074074        nan        nan\n",
      "        nan 0.19259259        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.64444444        nan\n",
      "        nan        nan 0.77037037        nan        nan        nan\n",
      "        nan        nan        nan 0.58518519        nan        nan\n",
      " 0.04444444        nan        nan        nan        nan 0.2\n",
      "        nan        nan]\n",
      "[         nan          nan          nan          nan          nan\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan 511.6                 nan          nan\n",
      " 419.5                 nan          nan          nan 458.55555556\n",
      "          nan          nan          nan          nan          nan\n",
      "          nan          nan          nan 412.                  nan\n",
      "          nan          nan 393.33333333          nan          nan\n",
      "          nan          nan          nan          nan 414.52777778\n",
      "          nan          nan 518.5                 nan          nan\n",
      "          nan          nan 457.2                 nan          nan]\n"
     ]
    }
   ],
   "source": [
    "print(scores[1][:50])\n",
    "print(dist[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"wheel.npy\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "gallery_folder = '/media/qcuong98/BackUp1/Dataset/AIC20_track2_reid/AIC20_track2/AIC20_ReID/image_test'\n",
    "\n",
    "threshold = 0.40\n",
    "\n",
    "visualize_folder = 'visualize_false_wheels_0.40'\n",
    "\n",
    "os.mkdir(visualize_folder)\n",
    "for i in range(N_QUERIES):\n",
    "    query_id = i + 1\n",
    "    if (np.all(np.isnan(scores[i]))):\n",
    "        continue\n",
    "    d = os.path.join(visualize_folder, str(query_id))\n",
    "    os.mkdir(d)\n",
    "    for j in range(N_TRACKLETS):\n",
    "        if (not np.isnan(scores[i][j])) and scores[i][j] < threshold:\n",
    "            gallery_id = tracks[j][0]\n",
    "            shutil.copyfile(os.path.join(gallery_folder, gallery_id), os.path.join(d, gallery_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
