{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIPLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import TripletDataset\n",
    "\n",
    "root_dir = '/home/cuong/AIC20-Track2/AIC20_track2/AIC20_ReID/image_train'\n",
    "train_csv = 'cls_train.csv'\n",
    "val_csv = 'cls_val.csv'\n",
    "label_json = 'train_image_metadata.json'\n",
    "\n",
    "size = (224, 224)\n",
    "\n",
    "triplet_train_dataset = TripletDataset(root_dir, train_csv, label_json,\n",
    "                                       transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),  \n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "triplet_val_dataset = TripletDataset(root_dir, val_csv, label_json,\n",
    "                                     transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),\n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "\n",
    "batch_size = 8\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_val_loader = torch.utils.data.DataLoader(triplet_val_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EfficientNetExtractor, TripletNet\n",
    "from losses import TripletLoss\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EfficientNetExtractor('b4')\n",
    "model = TripletNet(embedding_net)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 10\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuong/AIC20-Track2/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/24968 (0%)]\tLoss: 20.248615\n",
      "Train: [800/24968 (3%)]\tLoss: 5.829070\n",
      "Train: [1600/24968 (6%)]\tLoss: 1.237344\n",
      "Train: [2400/24968 (10%)]\tLoss: 1.244611\n",
      "Train: [3200/24968 (13%)]\tLoss: 1.033357\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.841692\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.697177\n",
      "Train: [5600/24968 (22%)]\tLoss: 1.053713\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.644551\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.644219\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.557796\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.604043\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.569363\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.577761\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.396554\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.539837\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.406357\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.351990\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.410573\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.443144\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.436478\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.283479\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.409652\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.340263\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.303230\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.324211\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.334927\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.252173\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.255329\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.285812\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.209264\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.235098\n",
      "Epoch: 1/10. Train set: Average loss: 0.7058\n",
      "Epoch: 1/10. Validation set: Average loss: 0.2255\n",
      "Train: [0/24968 (0%)]\tLoss: 0.148302\n",
      "Train: [800/24968 (3%)]\tLoss: 0.169086\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.192638\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.249170\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.187643\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.206506\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.197363\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.244113\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.182899\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.182849\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.193347\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.174123\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.192819\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.171110\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.169968\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.263668\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.193025\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.155466\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.116698\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.155315\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.193490\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.215739\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.199876\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.179108\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.214722\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.178228\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.223904\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.164338\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.142984\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.172567\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.154170\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.173262\n",
      "Epoch: 2/10. Train set: Average loss: 0.1874\n",
      "Epoch: 2/10. Validation set: Average loss: 0.1631\n",
      "Train: [0/24968 (0%)]\tLoss: 0.561668\n",
      "Train: [800/24968 (3%)]\tLoss: 0.186773\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.215257\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.181071\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.167656\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.165461\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.155089\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.191089\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.174662\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.125064\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.153388\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.168048\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.162877\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.181203\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.198879\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.149393\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.185630\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.158964\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.198493\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.149671\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.136768\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.148792\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.196781\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.174199\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.151284\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.162337\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.123139\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.110468\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.149358\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.114485\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.138650\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.137751\n",
      "Epoch: 3/10. Train set: Average loss: 0.1619\n",
      "Epoch: 3/10. Validation set: Average loss: 0.2434\n",
      "Train: [0/24968 (0%)]\tLoss: 0.000000\n",
      "Train: [800/24968 (3%)]\tLoss: 0.242052\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.249123\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.104538\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.112787\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.143873\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.147937\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.138285\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.193157\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.168152\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.174735\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.184478\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.126299\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.146117\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.087141\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.119872\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.139685\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.107917\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.158287\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.117033\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.134661\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.133289\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.118852\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.094093\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.117274\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.097666\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.167004\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.256618\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.191772\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.124226\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.097483\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.126368\n",
      "Epoch: 4/10. Train set: Average loss: 0.1457\n",
      "Epoch: 4/10. Validation set: Average loss: 0.2706\n",
      "Train: [0/24968 (0%)]\tLoss: 0.335581\n",
      "Train: [800/24968 (3%)]\tLoss: 0.141782\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.138671\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.125107\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.101562\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.114632\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.129199\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.111055\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.120745\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.146467\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.140707\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.106365\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.106342\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.107338\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.078810\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.097381\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.116047\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.134963\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.108276\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.124416\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.149432\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.070040\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.089917\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.110750\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.110404\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.078599\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.128929\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.155877\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.110603\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.179475\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.113776\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.155426\n",
      "Epoch: 5/10. Train set: Average loss: 0.1191\n",
      "Epoch: 5/10. Validation set: Average loss: 0.1891\n",
      "Train: [0/24968 (0%)]\tLoss: 0.000000\n",
      "Train: [800/24968 (3%)]\tLoss: 0.111295\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.072393\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.102767\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.055439\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.144888\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.073891\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.118814\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.099399\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.181110\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.089092\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.058170\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.144511\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.096111\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.127486\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.128956\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.125531\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.099182\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.151764\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.100003\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.118425\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.095058\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.094400\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.145274\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.080091\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.080897\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.099486\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.112966\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.103655\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.129677\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.077985\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.075280\n",
      "Epoch: 6/10. Train set: Average loss: 0.1071\n",
      "Epoch: 6/10. Validation set: Average loss: 0.1869\n",
      "Train: [0/24968 (0%)]\tLoss: 0.144897\n",
      "Train: [800/24968 (3%)]\tLoss: 0.107810\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.105289\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.086831\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.060574\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.121933\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.129292\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.133359\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.136129\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.135156\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.093430\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.108710\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.093423\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.108091\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.060324\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.084892\n",
      "Train: [12800/24968 (51%)]\tLoss: 0.065283\n",
      "Train: [13600/24968 (54%)]\tLoss: 0.135121\n",
      "Train: [14400/24968 (58%)]\tLoss: 0.107056\n",
      "Train: [15200/24968 (61%)]\tLoss: 0.101462\n",
      "Train: [16000/24968 (64%)]\tLoss: 0.071346\n",
      "Train: [16800/24968 (67%)]\tLoss: 0.132983\n",
      "Train: [17600/24968 (70%)]\tLoss: 0.086165\n",
      "Train: [18400/24968 (74%)]\tLoss: 0.081941\n",
      "Train: [19200/24968 (77%)]\tLoss: 0.069030\n",
      "Train: [20000/24968 (80%)]\tLoss: 0.088675\n",
      "Train: [20800/24968 (83%)]\tLoss: 0.104241\n",
      "Train: [21600/24968 (87%)]\tLoss: 0.067624\n",
      "Train: [22400/24968 (90%)]\tLoss: 0.133538\n",
      "Train: [23200/24968 (93%)]\tLoss: 0.097889\n",
      "Train: [24000/24968 (96%)]\tLoss: 0.089925\n",
      "Train: [24800/24968 (99%)]\tLoss: 0.068218\n",
      "Epoch: 7/10. Train set: Average loss: 0.0997\n",
      "Epoch: 7/10. Validation set: Average loss: 0.2671\n",
      "Train: [0/24968 (0%)]\tLoss: 0.078966\n",
      "Train: [800/24968 (3%)]\tLoss: 0.201302\n",
      "Train: [1600/24968 (6%)]\tLoss: 0.129315\n",
      "Train: [2400/24968 (10%)]\tLoss: 0.103730\n",
      "Train: [3200/24968 (13%)]\tLoss: 0.069115\n",
      "Train: [4000/24968 (16%)]\tLoss: 0.106149\n",
      "Train: [4800/24968 (19%)]\tLoss: 0.065594\n",
      "Train: [5600/24968 (22%)]\tLoss: 0.075097\n",
      "Train: [6400/24968 (26%)]\tLoss: 0.073249\n",
      "Train: [7200/24968 (29%)]\tLoss: 0.029418\n",
      "Train: [8000/24968 (32%)]\tLoss: 0.038605\n",
      "Train: [8800/24968 (35%)]\tLoss: 0.049853\n",
      "Train: [9600/24968 (38%)]\tLoss: 0.040536\n",
      "Train: [10400/24968 (42%)]\tLoss: 0.096499\n",
      "Train: [11200/24968 (45%)]\tLoss: 0.057911\n",
      "Train: [12000/24968 (48%)]\tLoss: 0.052702\n"
     ]
    }
   ],
   "source": [
    "fit(triplet_train_loader, triplet_val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'triplet-b4-200403.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
