{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIPLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import TripletDataset\n",
    "\n",
    "root_dir = '../AIC20_ReID/image_train'\n",
    "train_csv = 'metadata/cls_train.csv'\n",
    "val_csv = 'metadata/cls_val.csv'\n",
    "label_json = 'metadata/train_image_metadata.json'\n",
    "\n",
    "size = (224, 224)\n",
    "\n",
    "triplet_train_dataset = TripletDataset(root_dir, train_csv, label_json,\n",
    "                                       transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),  \n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "triplet_val_dataset = TripletDataset(root_dir, val_csv, label_json,\n",
    "                                     transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),\n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "\n",
    "batch_size = 8\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_val_loader = torch.utils.data.DataLoader(triplet_val_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EfficientNetExtractor, TripletNet\n",
    "from losses import TripletLoss\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EfficientNetExtractor('b4')\n",
    "model = TripletNet(embedding_net)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuong/AIC20-Track2/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/25585 (0%)]\tLoss: 24.244934\n"
     ]
    }
   ],
   "source": [
    "fit(triplet_train_loader, triplet_val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'weights/triplet-b4-200404.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLINE TRIPLET LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import ImageFolderDataset\n",
    "from datasets import BalancedBatchSampler\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "root_dir = '../AIC20_ReID/image_train'\n",
    "train_csv = 'metadata/cls_train.csv'\n",
    "val_csv = 'metadata/cls_val.csv'\n",
    "label_json = 'metadata/train_image_metadata.json'\n",
    "\n",
    "size = (224, 224)\n",
    "\n",
    "def get_images_labels(vehicle_csv, label_json):\n",
    "    with open(label_json, 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "    image_names = []\n",
    "    labels = []\n",
    "    with open(vehicle_csv, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            vehicle_id = row[0]\n",
    "            for cam_id in data_dict[vehicle_id]:\n",
    "                image_names += [image_name for image_name in data_dict[vehicle_id][cam_id]]\n",
    "                labels += [int(vehicle_id) for image_name in data_dict[vehicle_id][cam_id]]\n",
    "    return image_names, labels\n",
    "\n",
    "train_image_names, train_labels = get_images_labels(train_csv, label_json) \n",
    "val_image_names, val_labels = get_images_labels(val_csv, label_json) \n",
    "\n",
    "train_dataset = ImageFolderDataset(root_dir, train_image_names, train_labels,\n",
    "                                       transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),  \n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "val_dataset = ImageFolderDataset(root_dir, val_image_names, val_labels,\n",
    "                                     transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),\n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "\n",
    "\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset.labels, n_classes=5, n_samples=5)\n",
    "val_batch_sampler = BalancedBatchSampler(val_dataset.labels, n_classes=5, n_samples=5)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_val_loader = torch.utils.data.DataLoader(val_dataset, batch_sampler=val_batch_sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EfficientNetExtractor\n",
    "from losses import OnlineTripletLoss\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EfficientNetExtractor('b4')\n",
    "model = embedding_net\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuong/AIC20-Track2/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/25585 (0%)]\tLoss: 53.939754\tAverage nonzero triplets: 47.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 11.390418\tAverage nonzero triplets: 41.24752475247525\n",
      "Train: [5000/25585 (20%)]\tLoss: 4.701021\tAverage nonzero triplets: 35.90049751243781\n",
      "Train: [7500/25585 (29%)]\tLoss: 4.039120\tAverage nonzero triplets: 32.08305647840532\n",
      "Train: [10000/25585 (39%)]\tLoss: 3.847635\tAverage nonzero triplets: 29.576059850374065\n",
      "Train: [12500/25585 (49%)]\tLoss: 2.920765\tAverage nonzero triplets: 27.41117764471058\n",
      "Train: [15000/25585 (59%)]\tLoss: 2.678268\tAverage nonzero triplets: 25.798668885191347\n",
      "Train: [17500/25585 (68%)]\tLoss: 2.041569\tAverage nonzero triplets: 24.546362339514978\n",
      "Train: [20000/25585 (78%)]\tLoss: 1.928217\tAverage nonzero triplets: 23.621722846441948\n",
      "Train: [22500/25585 (88%)]\tLoss: 1.621420\tAverage nonzero triplets: 22.67258601553829\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.750617\tAverage nonzero triplets: 22.072927072927072\n",
      "Epoch: 1/20. Train set: Average loss: 3.6900\tAverage nonzero triplets: 22.01759530791789\n",
      "Epoch: 1/20. Validation set: Average loss: 1.1785\tAverage nonzero triplets: 16.611479028697573\n",
      "Train: [0/25585 (0%)]\tLoss: 1.117541\tAverage nonzero triplets: 17.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.521827\tAverage nonzero triplets: 15.247524752475247\n",
      "Train: [5000/25585 (20%)]\tLoss: 1.445252\tAverage nonzero triplets: 16.029850746268657\n",
      "Train: [7500/25585 (29%)]\tLoss: 1.450628\tAverage nonzero triplets: 15.621262458471762\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.378815\tAverage nonzero triplets: 14.937655860349127\n",
      "Train: [12500/25585 (49%)]\tLoss: 1.606100\tAverage nonzero triplets: 14.756487025948104\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.242388\tAverage nonzero triplets: 14.903494176372712\n",
      "Train: [17500/25585 (68%)]\tLoss: 1.388408\tAverage nonzero triplets: 14.881597717546363\n",
      "Train: [20000/25585 (78%)]\tLoss: 1.467705\tAverage nonzero triplets: 15.077403245942572\n",
      "Train: [22500/25585 (88%)]\tLoss: 1.419984\tAverage nonzero triplets: 14.982241953385127\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.376216\tAverage nonzero triplets: 14.99000999000999\n",
      "Epoch: 2/20. Train set: Average loss: 1.4310\tAverage nonzero triplets: 14.95210166177908\n",
      "Epoch: 2/20. Validation set: Average loss: 0.9645\tAverage nonzero triplets: 21.178807947019866\n",
      "Train: [0/25585 (0%)]\tLoss: 1.021484\tAverage nonzero triplets: 21.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.187358\tAverage nonzero triplets: 14.94059405940594\n",
      "Train: [5000/25585 (20%)]\tLoss: 1.333969\tAverage nonzero triplets: 14.666666666666666\n",
      "Train: [7500/25585 (29%)]\tLoss: 1.355525\tAverage nonzero triplets: 14.817275747508306\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.255743\tAverage nonzero triplets: 14.630922693266832\n",
      "Train: [12500/25585 (49%)]\tLoss: 1.354338\tAverage nonzero triplets: 14.86626746506986\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.166564\tAverage nonzero triplets: 14.615640599001663\n",
      "Train: [17500/25585 (68%)]\tLoss: 1.405265\tAverage nonzero triplets: 14.463623395149787\n",
      "Train: [20000/25585 (78%)]\tLoss: 1.222532\tAverage nonzero triplets: 13.958801498127341\n",
      "Train: [22500/25585 (88%)]\tLoss: 1.295633\tAverage nonzero triplets: 13.781354051054384\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.223449\tAverage nonzero triplets: 13.679320679320679\n",
      "Epoch: 3/20. Train set: Average loss: 1.2885\tAverage nonzero triplets: 13.612903225806452\n",
      "Epoch: 3/20. Validation set: Average loss: 1.2946\tAverage nonzero triplets: 18.781456953642383\n",
      "Train: [0/25585 (0%)]\tLoss: 0.561387\tAverage nonzero triplets: 6.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.287618\tAverage nonzero triplets: 13.049504950495049\n",
      "Train: [5000/25585 (20%)]\tLoss: 1.243282\tAverage nonzero triplets: 13.850746268656716\n",
      "Train: [7500/25585 (29%)]\tLoss: 1.100657\tAverage nonzero triplets: 13.813953488372093\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.354708\tAverage nonzero triplets: 13.802992518703242\n",
      "Train: [12500/25585 (49%)]\tLoss: 1.197670\tAverage nonzero triplets: 13.850299401197605\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.166420\tAverage nonzero triplets: 13.662229617304492\n",
      "Train: [17500/25585 (68%)]\tLoss: 1.299842\tAverage nonzero triplets: 13.661911554921542\n",
      "Train: [20000/25585 (78%)]\tLoss: 1.062080\tAverage nonzero triplets: 13.504369538077404\n",
      "Train: [22500/25585 (88%)]\tLoss: 1.283480\tAverage nonzero triplets: 13.400665926748058\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.084369\tAverage nonzero triplets: 13.26973026973027\n",
      "Epoch: 4/20. Train set: Average loss: 1.2067\tAverage nonzero triplets: 13.225806451612904\n",
      "Epoch: 4/20. Validation set: Average loss: 1.2515\tAverage nonzero triplets: 16.172185430463575\n",
      "Train: [0/25585 (0%)]\tLoss: 2.284382\tAverage nonzero triplets: 20.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.141684\tAverage nonzero triplets: 12.732673267326733\n",
      "Train: [5000/25585 (20%)]\tLoss: 1.140628\tAverage nonzero triplets: 12.422885572139304\n",
      "Train: [7500/25585 (29%)]\tLoss: 1.115487\tAverage nonzero triplets: 12.295681063122924\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.156305\tAverage nonzero triplets: 11.930174563591022\n",
      "Train: [12500/25585 (49%)]\tLoss: 1.247031\tAverage nonzero triplets: 12.243512974051896\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.166002\tAverage nonzero triplets: 12.359400998336106\n",
      "Train: [17500/25585 (68%)]\tLoss: 1.149071\tAverage nonzero triplets: 12.171184022824537\n",
      "Train: [20000/25585 (78%)]\tLoss: 1.106210\tAverage nonzero triplets: 12.099875156054932\n",
      "Train: [22500/25585 (88%)]\tLoss: 1.103904\tAverage nonzero triplets: 12.031076581576027\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.077387\tAverage nonzero triplets: 11.945054945054945\n",
      "Epoch: 5/20. Train set: Average loss: 1.1457\tAverage nonzero triplets: 11.93939393939394\n",
      "Epoch: 5/20. Validation set: Average loss: 1.3497\tAverage nonzero triplets: 16.280353200883003\n",
      "Train: [0/25585 (0%)]\tLoss: 0.648399\tAverage nonzero triplets: 9.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.261846\tAverage nonzero triplets: 12.663366336633663\n",
      "Train: [5000/25585 (20%)]\tLoss: 1.151602\tAverage nonzero triplets: 12.656716417910447\n",
      "Train: [7500/25585 (29%)]\tLoss: 1.130885\tAverage nonzero triplets: 12.644518272425248\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.232139\tAverage nonzero triplets: 12.54364089775561\n",
      "Train: [12500/25585 (49%)]\tLoss: 1.031438\tAverage nonzero triplets: 12.211576846307386\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.233377\tAverage nonzero triplets: 12.136439267886855\n",
      "Train: [17500/25585 (68%)]\tLoss: 1.011323\tAverage nonzero triplets: 12.05848787446505\n",
      "Train: [20000/25585 (78%)]\tLoss: 1.136215\tAverage nonzero triplets: 11.801498127340825\n",
      "Train: [22500/25585 (88%)]\tLoss: 1.066658\tAverage nonzero triplets: 11.704772475027747\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.082189\tAverage nonzero triplets: 11.491508491508492\n",
      "Epoch: 6/20. Train set: Average loss: 1.1339\tAverage nonzero triplets: 11.562072336265885\n",
      "Epoch: 6/20. Validation set: Average loss: 1.1334\tAverage nonzero triplets: 18.841059602649008\n",
      "Train: [0/25585 (0%)]\tLoss: 0.505795\tAverage nonzero triplets: 4.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.056629\tAverage nonzero triplets: 10.455445544554456\n",
      "Train: [5000/25585 (20%)]\tLoss: 1.148403\tAverage nonzero triplets: 11.348258706467663\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.981652\tAverage nonzero triplets: 10.611295681063122\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.274625\tAverage nonzero triplets: 11.124688279301745\n",
      "Train: [12500/25585 (49%)]\tLoss: 1.049366\tAverage nonzero triplets: 10.982035928143713\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.098637\tAverage nonzero triplets: 10.941763727121463\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.985491\tAverage nonzero triplets: 10.962910128388017\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.957421\tAverage nonzero triplets: 10.82896379525593\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.989022\tAverage nonzero triplets: 10.72142064372919\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.095334\tAverage nonzero triplets: 10.786213786213786\n",
      "Epoch: 7/20. Train set: Average loss: 1.0593\tAverage nonzero triplets: 10.730205278592376\n",
      "Epoch: 7/20. Validation set: Average loss: 0.9842\tAverage nonzero triplets: 13.94260485651214\n",
      "Train: [0/25585 (0%)]\tLoss: 0.000000\tAverage nonzero triplets: 1.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.882378\tAverage nonzero triplets: 8.94059405940594\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.658061\tAverage nonzero triplets: 8.228855721393035\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.722602\tAverage nonzero triplets: 7.740863787375416\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.628283\tAverage nonzero triplets: 7.259351620947631\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.692899\tAverage nonzero triplets: 7.1437125748503\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.674856\tAverage nonzero triplets: 6.9866888519134775\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.527833\tAverage nonzero triplets: 6.75320970042796\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.461992\tAverage nonzero triplets: 6.424469413233458\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.596639\tAverage nonzero triplets: 6.374028856825749\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.487026\tAverage nonzero triplets: 6.1998001998002\n",
      "Epoch: 8/20. Train set: Average loss: 0.6324\tAverage nonzero triplets: 6.191593352883675\n",
      "Epoch: 8/20. Validation set: Average loss: 0.9374\tAverage nonzero triplets: 10.693156732891833\n",
      "Train: [0/25585 (0%)]\tLoss: 1.411639\tAverage nonzero triplets: 13.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.391546\tAverage nonzero triplets: 4.178217821782178\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.607300\tAverage nonzero triplets: 4.592039800995025\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.526591\tAverage nonzero triplets: 4.568106312292358\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.609899\tAverage nonzero triplets: 4.7182044887780545\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.411486\tAverage nonzero triplets: 4.562874251497006\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.533063\tAverage nonzero triplets: 4.549084858569052\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.523706\tAverage nonzero triplets: 4.6676176890156915\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.503351\tAverage nonzero triplets: 4.729088639200999\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.534822\tAverage nonzero triplets: 4.645948945615983\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.427153\tAverage nonzero triplets: 4.549450549450549\n",
      "Epoch: 9/20. Train set: Average loss: 0.5067\tAverage nonzero triplets: 4.521016617790812\n",
      "Epoch: 9/20. Validation set: Average loss: 0.9777\tAverage nonzero triplets: 10.01103752759382\n",
      "Train: [0/25585 (0%)]\tLoss: 1.050374\tAverage nonzero triplets: 6.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.609589\tAverage nonzero triplets: 5.297029702970297\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.545400\tAverage nonzero triplets: 5.159203980099503\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.419489\tAverage nonzero triplets: 4.48172757475083\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.312581\tAverage nonzero triplets: 4.2443890274314215\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.419176\tAverage nonzero triplets: 4.147704590818363\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.430688\tAverage nonzero triplets: 4.096505823627288\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.473136\tAverage nonzero triplets: 4.152639087018545\n"
     ]
    }
   ],
   "source": [
    "fit(online_train_loader, online_val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'weights/onlinetriplet-b4-200406-semihardest.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
