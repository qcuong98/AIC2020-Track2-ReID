{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from trainer import fit\n",
    "import numpy as np\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIPLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import TripletDataset\n",
    "from random_erasing import RandomErasing\n",
    "\n",
    "root_dir = '../AIC20_ReID/image_train'\n",
    "train_csv = 'metadata/cls_train.csv'\n",
    "val_csv = 'metadata/cls_val.csv'\n",
    "label_json = 'metadata/train_image_metadata.json'\n",
    "\n",
    "size = (224, 224)\n",
    "\n",
    "triplet_train_dataset = TripletDataset(root_dir, train_csv, label_json,\n",
    "                                       transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),  \n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        RandomErasing(0.5, mean=[0.0, 0.0, 0.0])\n",
    "                                      ]))\n",
    "triplet_val_dataset = TripletDataset(root_dir, val_csv, label_json,\n",
    "                                     transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),\n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "\n",
    "batch_size = 8\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_val_loader = torch.utils.data.DataLoader(triplet_val_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EfficientNetExtractor, TripletNet\n",
    "from losses import TripletLoss\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EfficientNetExtractor('b4')\n",
    "model = TripletNet(embedding_net)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 30\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuong/AIC20-Track2/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/25585 (0%)]\tLoss: 24.244934\n"
     ]
    }
   ],
   "source": [
    "fit(triplet_train_loader, triplet_val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'weights/triplet-b4-200404.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLINE TRIPLET LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import ImageFolderDataset\n",
    "from datasets import BalancedBatchSampler\n",
    "from random_erasing import RandomErasing\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "root_dir = '../AIC20_ReID/image_train'\n",
    "train_csv = 'metadata/cls_train.csv'\n",
    "val_csv = 'metadata/cls_val.csv'\n",
    "label_json = 'metadata/train_image_metadata.json'\n",
    "\n",
    "size = (224, 224)\n",
    "\n",
    "def get_images_labels(vehicle_csv, label_json):\n",
    "    with open(label_json, 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "    image_names = []\n",
    "    labels = []\n",
    "    with open(vehicle_csv, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            vehicle_id = row[0]\n",
    "            for cam_id in data_dict[vehicle_id]:\n",
    "                image_names += [image_name for image_name in data_dict[vehicle_id][cam_id]]\n",
    "                labels += [int(vehicle_id) for image_name in data_dict[vehicle_id][cam_id]]\n",
    "    return image_names, labels\n",
    "\n",
    "train_image_names, train_labels = get_images_labels(train_csv, label_json) \n",
    "val_image_names, val_labels = get_images_labels(val_csv, label_json) \n",
    "\n",
    "train_dataset = ImageFolderDataset(root_dir, train_image_names, train_labels,\n",
    "                                       transform = transforms.Compose([\n",
    "                                        transforms.Resize(size), \n",
    "                                        transforms.ToTensor()\n",
    "#                                         RandomErasing(0.5, mean=[0.0, 0.0, 0.0])\n",
    "                                      ]))\n",
    "val_dataset = ImageFolderDataset(root_dir, val_image_names, val_labels,\n",
    "                                     transform = transforms.Compose([\n",
    "                                        transforms.Resize(size),\n",
    "                                        transforms.ToTensor()\n",
    "                                      ]))\n",
    "\n",
    "\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(train_dataset.labels, n_classes=5, n_samples=5)\n",
    "val_batch_sampler = BalancedBatchSampler(val_dataset.labels, n_classes=5, n_samples=5)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "online_train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_batch_sampler, **kwargs)\n",
    "online_val_loader = torch.utils.data.DataLoader(val_dataset, batch_sampler=val_batch_sampler, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "# Set up the network and training parameters\n",
    "from networks import EfficientNetExtractor\n",
    "from losses import OnlineTripletLoss\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "\n",
    "margin = 1.\n",
    "embedding_net = EfficientNetExtractor('b4')\n",
    "model = embedding_net\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = OnlineTripletLoss(margin, HardNegativeTripletSelector(margin))\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 30\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuong/AIC20-Track2/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/25585 (0%)]\tLoss: 0.520392\tAverage nonzero triplets: 5.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 41.417661\tAverage nonzero triplets: 3.1584158415841586\n",
      "Train: [5000/25585 (20%)]\tLoss: 2.722173\tAverage nonzero triplets: 4.189054726368159\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.468619\tAverage nonzero triplets: 4.8604651162790695\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.527287\tAverage nonzero triplets: 4.867830423940149\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.486494\tAverage nonzero triplets: 4.8982035928143715\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.498774\tAverage nonzero triplets: 5.254575707154742\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.494967\tAverage nonzero triplets: 5.911554921540656\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.507124\tAverage nonzero triplets: 5.906367041198502\n",
      "Train: [22500/25585 (88%)]\tLoss: 3.943437\tAverage nonzero triplets: 5.642619311875694\n",
      "Train: [25000/25585 (98%)]\tLoss: 1.182802\tAverage nonzero triplets: 5.858141858141858\n",
      "Epoch: 1/30. Train set: Average loss: 5.1189\tAverage nonzero triplets: 5.916911045943304\n",
      "Epoch: 1/30. Validation set: Average loss: 24575.9591\tAverage nonzero triplets: 4.816777041942605\n",
      "Train: [0/25585 (0%)]\tLoss: 0.607232\tAverage nonzero triplets: 7.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.500566\tAverage nonzero triplets: 13.099009900990099\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.517292\tAverage nonzero triplets: 14.218905472636816\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.508837\tAverage nonzero triplets: 13.196013289036545\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.489174\tAverage nonzero triplets: 12.13216957605985\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.527469\tAverage nonzero triplets: 10.7624750499002\n",
      "Train: [15000/25585 (59%)]\tLoss: 6.398393\tAverage nonzero triplets: 9.682196339434276\n",
      "Train: [17500/25585 (68%)]\tLoss: 253.609453\tAverage nonzero triplets: 8.951497860199714\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.484031\tAverage nonzero triplets: 8.355805243445692\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.492994\tAverage nonzero triplets: 8.267480577136515\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.513916\tAverage nonzero triplets: 8.344655344655346\n",
      "Epoch: 2/30. Train set: Average loss: 25.8219\tAverage nonzero triplets: 8.316715542521994\n",
      "Epoch: 2/30. Validation set: Average loss: 115.4913\tAverage nonzero triplets: 5.955849889624724\n",
      "Train: [0/25585 (0%)]\tLoss: 0.472583\tAverage nonzero triplets: 6.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.501047\tAverage nonzero triplets: 6.138613861386139\n",
      "Train: [5000/25585 (20%)]\tLoss: 2.439777\tAverage nonzero triplets: 7.577114427860696\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.493494\tAverage nonzero triplets: 8.358803986710964\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.498634\tAverage nonzero triplets: 8.291770573566085\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.508207\tAverage nonzero triplets: 7.606786427145709\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.520219\tAverage nonzero triplets: 7.331114808652246\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.501304\tAverage nonzero triplets: 7.249643366619115\n",
      "Train: [20000/25585 (78%)]\tLoss: 8.984645\tAverage nonzero triplets: 6.98501872659176\n",
      "Train: [22500/25585 (88%)]\tLoss: 75.746691\tAverage nonzero triplets: 6.653718091009989\n",
      "Train: [25000/25585 (98%)]\tLoss: 4.959446\tAverage nonzero triplets: 6.469530469530469\n",
      "Epoch: 3/30. Train set: Average loss: 9.3121\tAverage nonzero triplets: 6.41446725317693\n",
      "Epoch: 3/30. Validation set: Average loss: 46.1433\tAverage nonzero triplets: 5.30242825607064\n",
      "Train: [0/25585 (0%)]\tLoss: 0.462000\tAverage nonzero triplets: 5.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.501809\tAverage nonzero triplets: 5.871287128712871\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.511980\tAverage nonzero triplets: 6.2288557213930345\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.538172\tAverage nonzero triplets: 5.916943521594685\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.513120\tAverage nonzero triplets: 5.917705735660848\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.479336\tAverage nonzero triplets: 5.976047904191617\n",
      "Train: [15000/25585 (59%)]\tLoss: 1.062983\tAverage nonzero triplets: 5.815307820299501\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.529900\tAverage nonzero triplets: 5.921540656205421\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.492044\tAverage nonzero triplets: 6.259675405742821\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.487623\tAverage nonzero triplets: 6.34739178690344\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.505221\tAverage nonzero triplets: 6.27972027972028\n",
      "Epoch: 4/30. Train set: Average loss: 0.5601\tAverage nonzero triplets: 6.281524926686217\n",
      "Epoch: 4/30. Validation set: Average loss: 8.2452\tAverage nonzero triplets: 7.799116997792495\n",
      "Train: [0/25585 (0%)]\tLoss: 0.272958\tAverage nonzero triplets: 5.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.498301\tAverage nonzero triplets: 5.0\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.609068\tAverage nonzero triplets: 4.706467661691542\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.509737\tAverage nonzero triplets: 5.102990033222591\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.620444\tAverage nonzero triplets: 5.187032418952619\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.508234\tAverage nonzero triplets: 5.307385229540918\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.512119\tAverage nonzero triplets: 5.3011647254575704\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.515029\tAverage nonzero triplets: 5.378031383737518\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.493000\tAverage nonzero triplets: 5.429463171036205\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.491801\tAverage nonzero triplets: 5.544950055493896\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.516565\tAverage nonzero triplets: 5.5754245754245755\n",
      "Epoch: 5/30. Train set: Average loss: 0.5264\tAverage nonzero triplets: 5.5982404692082115\n",
      "Epoch: 5/30. Validation set: Average loss: 1445.6788\tAverage nonzero triplets: 9.67991169977925\n",
      "Train: [0/25585 (0%)]\tLoss: 0.210594\tAverage nonzero triplets: 7.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.487010\tAverage nonzero triplets: 6.762376237623762\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.489718\tAverage nonzero triplets: 6.7611940298507465\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.484398\tAverage nonzero triplets: 6.308970099667774\n",
      "Train: [10000/25585 (39%)]\tLoss: 7.533797\tAverage nonzero triplets: 6.0099750623441395\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.457894\tAverage nonzero triplets: 5.802395209580839\n",
      "Train: [15000/25585 (59%)]\tLoss: 2.748010\tAverage nonzero triplets: 5.697171381031614\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.501018\tAverage nonzero triplets: 5.589158345221112\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.724431\tAverage nonzero triplets: 5.5418227215980025\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.476828\tAverage nonzero triplets: 5.3440621531631525\n",
      "Train: [25000/25585 (98%)]\tLoss: 4.580508\tAverage nonzero triplets: 5.262737262737263\n",
      "Epoch: 6/30. Train set: Average loss: 1.9279\tAverage nonzero triplets: 5.2082111436950145\n",
      "Epoch: 6/30. Validation set: Average loss: 0.5068\tAverage nonzero triplets: 6.415011037527594\n",
      "Train: [0/25585 (0%)]\tLoss: 0.581736\tAverage nonzero triplets: 3.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 2.116714\tAverage nonzero triplets: 4.0\n",
      "Train: [5000/25585 (20%)]\tLoss: 2.101269\tAverage nonzero triplets: 4.492537313432836\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.501025\tAverage nonzero triplets: 5.554817275747508\n",
      "Train: [10000/25585 (39%)]\tLoss: 14.568635\tAverage nonzero triplets: 5.817955112219451\n",
      "Train: [12500/25585 (49%)]\tLoss: 17.491179\tAverage nonzero triplets: 5.810379241516966\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.503014\tAverage nonzero triplets: 5.935108153078203\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.489627\tAverage nonzero triplets: 5.937232524964337\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.881626\tAverage nonzero triplets: 5.749063670411985\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.487465\tAverage nonzero triplets: 5.668146503884572\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.500853\tAverage nonzero triplets: 5.759240759240759\n",
      "Epoch: 7/30. Train set: Average loss: 3.8862\tAverage nonzero triplets: 5.771260997067449\n",
      "Epoch: 7/30. Validation set: Average loss: 4.0617\tAverage nonzero triplets: 8.461368653421633\n",
      "Train: [0/25585 (0%)]\tLoss: 0.547359\tAverage nonzero triplets: 5.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.504671\tAverage nonzero triplets: 5.99009900990099\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.505484\tAverage nonzero triplets: 6.164179104477612\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.513032\tAverage nonzero triplets: 6.196013289036545\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.516454\tAverage nonzero triplets: 6.224438902743142\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.512463\tAverage nonzero triplets: 6.179640718562874\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.489954\tAverage nonzero triplets: 6.222961730449251\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.484108\tAverage nonzero triplets: 6.252496433666191\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.520091\tAverage nonzero triplets: 6.278401997503121\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.473123\tAverage nonzero triplets: 6.305216426193119\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.492666\tAverage nonzero triplets: 6.283716283716283\n",
      "Epoch: 8/30. Train set: Average loss: 0.5010\tAverage nonzero triplets: 6.274682306940371\n",
      "Epoch: 8/30. Validation set: Average loss: 390.5929\tAverage nonzero triplets: 10.97130242825607\n",
      "Train: [0/25585 (0%)]\tLoss: 0.419344\tAverage nonzero triplets: 7.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.481324\tAverage nonzero triplets: 6.306930693069307\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.486327\tAverage nonzero triplets: 6.27363184079602\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.501763\tAverage nonzero triplets: 6.305647840531561\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.505134\tAverage nonzero triplets: 6.386533665835412\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.494734\tAverage nonzero triplets: 6.431137724550898\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.482031\tAverage nonzero triplets: 6.417637271214642\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.488399\tAverage nonzero triplets: 6.422253922967189\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.511712\tAverage nonzero triplets: 6.378277153558052\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.511807\tAverage nonzero triplets: 6.369589345172031\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.497184\tAverage nonzero triplets: 6.311688311688312\n",
      "Epoch: 9/30. Train set: Average loss: 0.4957\tAverage nonzero triplets: 6.301075268817204\n",
      "Epoch: 9/30. Validation set: Average loss: 7.9156\tAverage nonzero triplets: 10.434878587196469\n",
      "Train: [0/25585 (0%)]\tLoss: 0.561501\tAverage nonzero triplets: 5.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.489786\tAverage nonzero triplets: 5.603960396039604\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.523270\tAverage nonzero triplets: 5.6318407960199\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.490235\tAverage nonzero triplets: 5.504983388704319\n",
      "Train: [10000/25585 (39%)]\tLoss: 1.129238\tAverage nonzero triplets: 5.2817955112219455\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.518451\tAverage nonzero triplets: 5.2395209580838324\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.458737\tAverage nonzero triplets: 5.247920133111481\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.490495\tAverage nonzero triplets: 5.282453637660485\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.466138\tAverage nonzero triplets: 5.29338327091136\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.468872\tAverage nonzero triplets: 5.27857935627081\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.493841\tAverage nonzero triplets: 5.265734265734266\n",
      "Epoch: 10/30. Train set: Average loss: 0.5524\tAverage nonzero triplets: 5.273704789833822\n",
      "Epoch: 10/30. Validation set: Average loss: 0.5263\tAverage nonzero triplets: 9.73289183222958\n",
      "Train: [0/25585 (0%)]\tLoss: 0.528324\tAverage nonzero triplets: 9.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 1.361156\tAverage nonzero triplets: 4.841584158415841\n",
      "Train: [5000/25585 (20%)]\tLoss: 123.816384\tAverage nonzero triplets: 5.074626865671642\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.491970\tAverage nonzero triplets: 4.6112956810631225\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.474466\tAverage nonzero triplets: 4.413965087281795\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.664995\tAverage nonzero triplets: 4.191616766467066\n",
      "Train: [15000/25585 (59%)]\tLoss: 15.306908\tAverage nonzero triplets: 4.098169717138103\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.511043\tAverage nonzero triplets: 4.10413694721826\n",
      "Train: [20000/25585 (78%)]\tLoss: 0.496678\tAverage nonzero triplets: 4.1722846441947565\n",
      "Train: [22500/25585 (88%)]\tLoss: 0.725287\tAverage nonzero triplets: 4.168701442841288\n",
      "Train: [25000/25585 (98%)]\tLoss: 0.500238\tAverage nonzero triplets: 4.187812187812188\n",
      "Epoch: 11/30. Train set: Average loss: 14.1211\tAverage nonzero triplets: 4.1974584555229715\n",
      "Epoch: 11/30. Validation set: Average loss: 0.6350\tAverage nonzero triplets: 7.178807947019868\n",
      "Train: [0/25585 (0%)]\tLoss: 0.526744\tAverage nonzero triplets: 10.0\n",
      "Train: [2500/25585 (10%)]\tLoss: 0.473591\tAverage nonzero triplets: 4.762376237623762\n",
      "Train: [5000/25585 (20%)]\tLoss: 0.517659\tAverage nonzero triplets: 4.567164179104478\n",
      "Train: [7500/25585 (29%)]\tLoss: 0.752872\tAverage nonzero triplets: 4.561461794019934\n",
      "Train: [10000/25585 (39%)]\tLoss: 0.490802\tAverage nonzero triplets: 4.748129675810474\n",
      "Train: [12500/25585 (49%)]\tLoss: 0.508906\tAverage nonzero triplets: 4.7604790419161676\n",
      "Train: [15000/25585 (59%)]\tLoss: 0.499475\tAverage nonzero triplets: 4.750415973377704\n",
      "Train: [17500/25585 (68%)]\tLoss: 0.493181\tAverage nonzero triplets: 4.807417974322396\n"
     ]
    }
   ],
   "source": [
    "fit(online_train_loader, online_val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[AverageNonzeroTripletsMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'weights/onlinetriplet-b4-200406-hardest.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
